{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My_toolkits\\Python\\Python 3.9.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import  datasets\n",
    "from torchvision.transforms import Compose, ToTensor, ConvertImageDtype, Resize\n",
    "from torchvision.utils import  make_grid\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "from models import CGanGenerator, CGanDiscriminator, CGanTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SHAPE = (1,32,32)\n",
    "BATCH_SIZE = 32\n",
    "Z_DIM = 100\n",
    "EMBED_SIZE = 100\n",
    "NUM_CLASSES = 10\n",
    "CRITIC_INTERATIONS = 1\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'd:\\\\Entertainment\\\\HCMUT\\\\IAS_lab\\\\research\\\\gans-collection\\\\notebooks\\\\cgan\\\\../..\\\\models\\\\__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(IM_SHAPE[-1], antialias=True),\n",
    "    ConvertImageDtype(torch.float32)\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root='../../data', download=True,\n",
    "    transform=custom_transforms)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1041/1875 - lossD: 0.0509 - lossG: 4.3360"
     ]
    }
   ],
   "source": [
    "generator = CGanGenerator(NUM_CLASSES, EMBED_SIZE, Z_DIM, IM_SHAPE).to(device)\n",
    "discriminator =  CGanDiscriminator(NUM_CLASSES, IM_SHAPE).to(device)\n",
    "CGanTrainer(EPOCHS, generator, discriminator, loader, CRITIC_INTERATIONS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = torch.randn((100, Z_DIM)).to(device)\n",
    "labels = torch.LongTensor([[i for i in range(10)] for j in range(10)]).view(-1).to(device)\n",
    "out = generator(noises,labels)\n",
    "grid = make_grid(out, nrow=10, normalize=True)\n",
    "img = grid.detach().cpu().numpy().transpose((1,2,0))\n",
    "plt.imshow(img,vmin=0, vmax=1, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
