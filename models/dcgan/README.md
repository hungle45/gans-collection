# Unsupervised Representation Learning with Deep Convolutional Generative Adviersarial Networks
## Info
- **Author:** Alec Radford, Luke Metz, Soumith Chintala.
- **Link:** https://arxiv.org/pdf/1511.06434.pdf
- **Public date:** Jun 10, 2014.
- **Dataset:** `LSUN`, `Imagenet-1k`.
- **Tags**: `GANs`, `Unsupervised learning`.
 
## Summary
DCGAN stand for Deep Convolutional GAN. In DCGAN, Generator learns to generate images, and Discriminator learns to differentiate between images from a real dataset and images generated by Generator.

Architecture guildline:
- Replace all deterministic pooling functions (such as maxpooling) with strided convolutions.
- Eliminate the fully connected layer on top of convolutional features and replace it with global average pooling, which makes the model more stable but hurts the convergence speed.
- Use batch normalization to prevent the generator from collapsing all samples into a single point, which is one of the most common GAN failures. However, do not use batch norm at the generator's output or the discriminator's input.
- In the generator, use ReLU for all layers except the output, which uses Tanh. In the discriminator, use Leaky ReLU for all layers.
 
Experirment:
- Use the discriminator as a feature extractor.
- Inspire from the athrimetic operation on vector embedding ($v_{King} - v_{Man} + v_{Woman}$), they demonstrated that on the z vectors.
- Make the generator forget to draw the window by dropping all feature maps that are predicted to be features on the window by a simple logistic regression fitted on the second highest generator's layer.